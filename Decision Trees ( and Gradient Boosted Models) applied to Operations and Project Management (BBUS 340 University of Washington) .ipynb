{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are notes for my Operations Management course:\n",
    "At a high level we use operations to compete, then we endeavor to manage processes including: process strategy, process analysis, quality and performance, capacity planning, constraint management, lean systems.\n",
    "The next step is managing customer demand such as: forecasting (regression analysis e.g. Prophet forecasting) and inventory management.\n",
    "\n",
    "The last step is project management. \n",
    "\n",
    "There are both strategic and tactical choices in operations, whether it is for a specific product or application rollout. \n",
    "\n",
    "- Strategies win wars and these include: development of new capabilities, maintenance of existing capabilities, design of new processes, development and organization of value chains, key performance measures. \n",
    "\n",
    "- Tactical decisions help you win fights, these include: process improvement and performance measures, management and planning of projects, generation of production and staffing plans, inventory management, resource scheduling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before exploring machine learning applications in decision making, let's start of with some basics.\n",
    "We can use preference matrices to rate alternatives according to several performance criteria, all components need to be in the same scale (e.g. log scale). This seems overly simplistic, however still useful in decision making.\n",
    "Another useful tool for evaluating services or products is break-even analysis. How low must variable costs (VC) per unit be to break even? \n",
    "How low must fixed costs (FC) be to break even?\n",
    "\n",
    "Break-even analysis makes the assumption that all costs related to production can be divided into the two categories mentioned above (FC and VC)\n",
    "\n",
    "Q = the number of customers served or units produced per year, \n",
    "\n",
    "total VC = cQ\n",
    "\n",
    "F = FC \n",
    "\n",
    "Total cost = F + cQ\n",
    "\n",
    "Total revenue = pQ\n",
    "\n",
    "break-even: \n",
    "\n",
    "pQ = F + cQ\n",
    "\n",
    "Q = F / (p-c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "More interesting questions arise when we explore decision making with uncertainty and incorporate probability theory in our decisions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are schematic models of available alternatives and possible consequences, moreover they are useful with probabilistic events and sequential decisions. Conditional payoffs for each possible alternativ-event combination shown at the end of each combination. \n",
    "\n",
    "For each event node, we multiply the payoff of each even branch by the event's probability and add these products to get the event node's expected payoff.\n",
    "\n",
    "We use the expected value to formalize the value for each alternative.\n",
    "\n",
    "Now let's explore Decision trees with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all honesty, this is my first real exposure to decision trees, I have heard about the utility of gradient boosted models to win Kaggle competitions and calculated some binomial trees in Risk Modeling but this is definitely uncharted territory. Exciting time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started: \n",
    "source of content: Dr. Jason Brownlee\n",
    "\n",
    "Classification and Regression Trees (CART), machine learning solution for both labeled and continuous output (also different cost functions MSE vs. Gini coefficient).\n",
    "\n",
    "Specific to Decision trees the cost function for regress endeavors to be optimize the choice in split points\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use pandas to import and clean the data:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"banks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the gini index is the name of the cost function used to evaluate the splits in the data. \n",
    "\n",
    "A split in the data involves one input attribute and one value for that attribute, it can be used to divide training patterns into two groups of rows. \n",
    "\n",
    "A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. A perfect split results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group results in a Gini score of 0.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange \n",
    "from sklearn import tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1371, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a visualization we will create a pdf of the model structure and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank.pdf'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "dot_data= tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"bank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset. \n",
    "\n",
    "As with other classifiers, DecisionTreeClassifier  takes as input two arrays, here I set them as NumPy arrays, X the input, and Y the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
